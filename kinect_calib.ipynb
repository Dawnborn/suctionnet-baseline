{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.11575900786613977, 0.05667892633017958, 0.606)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假设的相机内参矩阵\n",
    "intrinsics = np.array([601.1693115234375 , 0.,         637.8362426757812,\n",
    "                    0. ,        600.8593139648438, 363.8018798828125,\n",
    "                    0.,           0.,           1.        ]).reshape((3,3))\n",
    "fx, fy = intrinsics[0,0], intrinsics[1,1]\n",
    "cx, cy = intrinsics[0,2], intrinsics[1,2]\n",
    "\n",
    "# 给定的像素坐标(u, v)和深度Z\n",
    "u, v, Z = 820, 350, 0.627 # (0.18999086222955386, -0.014402337594503479, 0.627)\n",
    "u, v, Z = 840, 507, 0.554 # (0.1863014618523999, 0.1320305048139165, 0.554)\n",
    "u, v, Z = 523, 420, 0.606 # (-0.11575900786613977, 0.05667892633017958, 0.606)\n",
    "\n",
    "# 计算XYZ坐标\n",
    "X = (u - cx) * Z / fx\n",
    "Y = (v - cy) * Z / fy\n",
    "\n",
    "X, Y, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zhanglei: [[0. 0.]\n",
      " [1. 1.]\n",
      " [2. 2.]]\n",
      "[[ 0.99948355 -0.00212897 -0.03206386  0.36518713]\n",
      " [ 0.01229568 -0.89653382  0.44280461 -0.60687769]\n",
      " [-0.02968905 -0.44297017 -0.89604464  0.68282678]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    " \n",
    "def hand_eye_calib(points_cam, points_rob, vis=True):\n",
    "    cam = o3d.geometry.PointCloud()\n",
    "    rob = o3d.geometry.PointCloud()\n",
    "    cam.points = o3d.utility.Vector3dVector(points_cam)\n",
    "    rob.points = o3d.utility.Vector3dVector(points_rob)\n",
    "    cam.paint_uniform_color([1, 0, 0])\n",
    "    rob.paint_uniform_color([0, 1, 0])\n",
    "    list_id_cam = list(range(len(points_cam)))\n",
    "    list_id_rob = list(range(len(points_rob)))\n",
    "    assert (len(list_id_cam) >= 3 and len(list_id_rob) >= 3)\n",
    "    assert (len(list_id_rob) == len(list_id_rob))\n",
    "    corr = np.zeros((len(list_id_cam), 2))\n",
    "    corr[:, 0] = list_id_cam\n",
    "    corr[:, 1] = list_id_rob\n",
    "    print(\"zhanglei:\", corr)\n",
    "    hand_eye_p2p = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    final_hand_eye = hand_eye_p2p.compute_transformation(cam, rob, o3d.utility.Vector2iVector(corr))\n",
    "    print(final_hand_eye)\n",
    "    \n",
    "    if vis:\n",
    "        o3d.visualization.draw_geometries([cam.transform(final_hand_eye), rob])\n",
    "    return final_hand_eye\n",
    " \n",
    "\n",
    "# points_cam = np.array(\n",
    "#     [[-0.02075,  0.02597,  1.15615],\n",
    "#      [0.15487, 0.05592,   1.11818],\n",
    "#      [0.13379, -0.04346, 1.12400]] # camera 坐标系下的点\n",
    "# )\n",
    "points_cam = np.array(\n",
    "    [[0.18999086222955386, -0.014402337594503479, 0.627],\n",
    "     [0.1863014618523999, 0.1320305048139165, 0.554],\n",
    "     [-0.11575900786613977, 0.05667892633017958, 0.606]]\n",
    ")\n",
    "\n",
    "# points_rob = np.array(\n",
    "#     [[0.2449664800249867, -0.36223072817512053, 0.005815013802759242],\n",
    "#      [0.42321621634623396, -0.3965202364977765, 0.0071650325018939726],\n",
    "#      [0.4039400827566261, -0.29704639533281213, 0.007148857394119079]]\n",
    "# )\n",
    "points_rob = np.array([[0.5315284341408161, -0.31606744270290527, 0.12170995566217216],\n",
    "[0.5290902012372901, -0.47521642506733847, 0.12233675564088844],\n",
    "[0.23767231568711195, -0.3911261471407533, 0.11825402441267664]]\n",
    ")\n",
    "\n",
    "final_hand_eye = hand_eye_calib(points_cam, points_rob)\n",
    "\n",
    "# cam\n",
    "# [[-0.25047815, - 0.13900883,  1.50225439],\n",
    "# [-0.02924966,  0.18728401,  1.46627832],\n",
    "# [-0.38933743,  0.22643211,  1.53078687]]\n",
    "\n",
    "# rob\n",
    "# [[-0.10405,-0.60642,0.01483],\n",
    "# [0.22889, -0.39027,0.01612],\n",
    "# [0.25768,-0.75808,0.01991]]\n",
    "\n",
    "# hand_eye_result\n",
    "# [[0.03031916,  0.99942402,  0.01524406,  0.0198895],\n",
    "#  [0.9824005,  -0.02698358, -0.18482733, -0.08615673],\n",
    "#  [-0.18430953, 0.02057958, -0.98265278,  1.44772014],\n",
    "#  [0.,          0.,          0.,          1.]]\n",
    "hand_eye_m = final_hand_eye\n",
    "\n",
    "# frame base\n",
    "base_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.5, origin=[0,0,0])\n",
    "cam_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.2)\n",
    "cam_frame.transform(np.reshape(hand_eye_m, (4,4)))\n",
    "o3d.visualization.draw_geometries([base_frame, cam_frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"/data/hdd1/storage/junpeng/ws_anygrasp/suctionnet-baseline/color2.png\")\n",
    "depth = np.load(\"/data/hdd1/storage/junpeng/ws_anygrasp/suctionnet-baseline/depth2.npy\")\n",
    "cloud = create_point_cloud_from_depth_image(depth,camera_info)\n",
    "\n",
    "point_cloud = o3d.geometry.PointCloud()\n",
    "point_cloud.points = o3d.utility.Vector3dVector(cloud)\n",
    "point_cloud.colors = o3d.utility.Vector3dVector(image.reshape(-1,3))\n",
    "o3d.visualization.draw_geometries([base_frame, cam_frame, point_cloud])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Using plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 模拟简单的图像和深度图数据\n",
    "# 真实应用中，image和depth将是实际的图像和深度图\n",
    "image = cv2.imread(\"/data/hdd1/storage/junpeng/ws_anygrasp/suctionnet-baseline/color2.png\")\n",
    "depth = np.load(\"/data/hdd1/storage/junpeng/ws_anygrasp/suctionnet-baseline/depth2.npy\")\n",
    "depth = depth/1000.\n",
    "\n",
    "# 模拟的相机内参矩阵\n",
    "intrinsics = np.array([601.1693115234375 , 0.,         637.8362426757812,\n",
    "                    0. ,        600.8593139648438, 363.8018798828125,\n",
    "                    0.,           0.,           1.        ]).reshape((3,3))\n",
    "K = intrinsics\n",
    "\n",
    "# 计算每个像素的XYZ坐标\n",
    "height, width = depth.shape\n",
    "X, Y = np.meshgrid(np.arange(width), np.arange(height))\n",
    "Z = depth\n",
    "X = (X - K[0, 2]) * Z / K[0, 0]\n",
    "Y = (Y - K[1, 2]) * Z / K[1, 1]\n",
    "\n",
    "# 将坐标和颜色值重塑为一维数组，以便于plotly处理\n",
    "X = X.flatten()\n",
    "Y = Y.flatten()\n",
    "Z = Z.flatten()\n",
    "colors = image.reshape(-1, 3) / 255.0  # 归一化颜色值\n",
    "\n",
    "# 使用plotly创建三维散点图\n",
    "kk = 3\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=X[::kk], y=Y[::kk], z=Z[::kk],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color=colors[::kk],                # 设置颜色\n",
    "        opacity=0.8\n",
    "    )\n",
    ")])\n",
    "\n",
    "# 设置图表布局\n",
    "fig.update_layout(\n",
    "    margin=dict(l=0, r=0, b=0, t=0),\n",
    "    scene=dict(\n",
    "        xaxis_title='X',\n",
    "        yaxis_title='Y',\n",
    "        zaxis_title='Z'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "import time\n",
    "\n",
    "def z_axis_to_quaternion(z_axis):\n",
    "    # 确保z_axis是单位向量\n",
    "    z_axis = z_axis / np.linalg.norm(z_axis)\n",
    "    \n",
    "    # 选择一个默认上方向，计算x_axis\n",
    "    y_axis_default = np.array([0, 1, 0])\n",
    "    x_axis = np.cross(y_axis_default, z_axis)\n",
    "    x_axis = x_axis / np.linalg.norm(x_axis)  # 归一化\n",
    "    \n",
    "    # 计算y_axis\n",
    "    y_axis = np.cross(z_axis, x_axis)\n",
    "    \n",
    "    # 从轴构建旋转矩阵\n",
    "    rotation_matrix = np.array([x_axis, y_axis, z_axis]).T\n",
    "    \n",
    "    # 将旋转矩阵转换为四元数\n",
    "    quaternion = R.from_matrix(rotation_matrix).as_quat()  # [x, y, z, w]\n",
    "    \n",
    "    return quaternion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suctionnet_baseline2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
